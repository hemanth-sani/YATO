### use # to comment out the configure item

### I/O ###
train_dir=/data/zqwang/Github-YATO/YATO-main/YATO-EXPERMENTS//RTE/train.convert.txt
dev_dir=/data/zqwang/Github-YATO/YATO-main/YATO-EXPERMENTS/RTE/dev.convert.txt
test_dir=/data/zqwang/Github-YATO/YATO-main/YATO-EXPERMENTS/RTE/dev.convert.txt
sentence_classification=true
words2sent=None
model_dir=/data/zqwang/Github-YATO/YATO-main/YATO-EXPERMENTS/

dset_dir=/data/zqwang/Github-YATO/YATO-main/YATO-EXPERMENTS/RTE/bert_base_gelu_RTE.dset

norm_word_emb=False
norm_char_emb=False
number_normalized=False
seg=True
word_emb_dim=50
char_emb_dim=30
MAX_SENTENCE_LENGTH=128

###NetworkConfiguration###
use_crf=False
use_char=False
char_seq_feature=CNN
use_word_seq=False
use_word_emb=False
word_seq_feature=LSTM
low_level_transformer=None
low_level_transformer_finetune=False
high_level_transformer=bert-base-uncased
high_level_transformer_finetune=True

###TrainingSetting###
status=train
optimizer=AdamW
scheduler=linear
iteration=3
batch_size=16
ave_batch_loss=False


###Hyperparameters###
cnn_layer=4
char_hidden_dim=50
hidden_dim=768
dropout=0.1
lstm_layer=2
bilstm=True
learning_rate=2e-5
gpu=True
device=cuda:0
clip=1